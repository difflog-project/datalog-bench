DatalogBench is a collection of Datalog programs from the literature in various fields including databases, information retrieval, and program analysis.

The primary goal of this collection is to benchmark techniques for learning Datalog programs from input-output data. This is an important problem studied in fields such as program synthesis and Inductive Logic Programming, with applications in a variety of domains such as bioinformatics, big-data analytics, natural language processing, networking, program analysis, and robotics.

Besides the target Datalog programs themselves, this collection includes input-output datasets for each program, as well as code to generate candidate rules using various methods of inducing syntactic bias, akin to syntax-guided synthesis (SyGuS) or template rules in meta-interpretive learning.

## 1. Rule Generation
All rule generation algorithms can be found in the <b>rule-gen</b> folder. There are four variants:<br><br>
<b>generate</b>, which is a standard brute-force rule generation algorithm. It first enumerates all possible combinations of relations and variables, then applies a number of filters to remove redundant and clearly incorrect rules. Notably, it filters any rules that have variables that match different types in different relations.
<br>
<b>generate-fast</b>, which, unlike <b>generate</b>, does not enumerate any rules whose types do not match the types of the relations, thus dramatically cutting down on the algorithm's runtime. However, this algorithm offers less control over the candidate rule set generated. The algorithm applies a number of filters to remove redundant and clearly incorrect rules as well.
<br>
<b>generate-back</b>, which is equivalent to <b>generate</b>, but inserts *Rule* relation at the front of each rule rather than the back.
<br>
<b>generate-negation</b>, which is equivalent to <b>generate</b>, but is capable of handling negation.
<br>

## 2. Benchmark Structure
Note that each benchmark may not contain all files listed below.

Additionally, a few benchmarks (*quickfoil-webkb* and *quickfoil-bongard*) contain variants: 
<br>
&emsp;*quickfoil-webkb* has 8 variants which are generated from different data sources but have similar size candidate rule sets.
<br>
&emsp;*quickfoil-bongard* has 10 variants which are generated from the same data source but have varying size candidate rule sets.

### 2.1 Input-Output Data

Input-output datasets are provided in two different formats, called primary and alternate, as described below.

##### Primary format
This format provides input data in <b>\*.facts</b> files and output data in <b>\*.expected</b> files. In particular, the tuples of each input relation <b>R</b> are provided in a file named <b>R.facts</b>, and the expected tuples of each output relation <b>S</b> are provided in a file named <b>S.expected</b>. 
<br>
##### Alternate format
This format provides all input-output data combined in a single <b>.d</b> file.
<br>

### 2.2 Rule Generation Data

Rule generation data is provided in two different formats, called primary and alternate, as described below.

##### Primary format
This format defines input and output relations for the rule generation algorithm in a <b>rules.t</b> file. There should be one <b>rules.t</b> file per benchmark. The rule generation algorithm takes <b>rules.t</b> as input, and enumerates every possible combination of candidate rules. It applies a number of filters to remove redundant and clearly incorrect rules, such as ensuring that the variable numbers are minimized left to right and that variables match the types of the relations throughout the rules. Finally, it produces a <b>rules.large.dl</b> file.
<br><br>
The candidate rules set generated by the rule generation algorithm using the provided rules.t file is stored in a <b>rules.large.dl</b> file. There should be at most one rules.large.dl file per benchmark. Note that rules.large.dl usually contains between 2 - 10 times the number of candidate rules as rules.small.dl. 
<br><br>
The auxillary rule set used to generate coprovenance for <b>rules.small.dl</b> and <b>rules.large.dl</b> are stored in <b>rules_notexists.small.dl</b> and <b>rules_notexists.large.dl</b>, respectively. Note that these rules are not part of the candidate rule set. <b>rules_notexists.large.dl</b> is created automatically by the candidate rule generation algorithm when generating <b>rules.large.dl</b>. There should be at most one <b>rules_notexists.small.dl</b> and at most one <b>rules_notexists.large.dl</b> file per benchmark.
<br><br>
The auxillary rule set used to generate allprovenance for <b>rules.small.dl</b> and <b>rules.large.dl</b> are stored in <b>rules_exists.small.dl</b> and <b>rules_exists.large.dl</b>, respectively. Note that these rules are not part of the candidate rule set. <b>rules_exists.large.dl</b> is created automatically by the candidate rule generation algorithm when generating <b>rules.large.dl</b>. There should be at most one <b>rules_exists.small.dl</b> and at most one <b>rules_exists.large.dl</b> file per benchmark.
<br><br>
The list of rule numbers which define the candidate rules the algorithm is able to access are stored in <b>ruleNames.small.txt</b> and <b>ruleNames.large.txt</b> for <b>rules.small.dl</b> and <b> rules.large.dl</b>, respectively. By default, rule numbers for all candidate rules are listed in the file. <b>ruleNames.large.txt</b> is created automatically by the candidate rule generation algorithm when generating <b>rules.large.dl</b>. There should be at most one <b>ruleNames.small.txt</b> and at most one <b>ruleNames.large.txt</b> file per benchmark.
<br>
##### Alternate format
This format provides rule template data in a <b>\*.tp</b> file, which is required for an alternate rule generation procedure from a previous project. In particular, the template data for benchmark <b>B</b> is provided in a file named <b>B.tp</b>. The should be at most one <b>\*.tp</b> file per benchmark.
<br><br>
The candidate rules set sourced from an alternate rule generation algorithm from a previous project is stored in a <b>rules.small.dl</b> file. There should be at most one <b>rules.small.dl</b> file per benchmark.
<br>


